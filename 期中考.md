# Lisi
### 1. keyword 是什麼？關鍵字 (或關鍵詞) 又是什麼？你覺得應該怎麼定義「一篇新聞裡的關鍵字是什麼？又該如何取出這些關鍵字？」此外「一篇新聞裡的 keyword 又是什麼？該怎麼取出來？」
在一個data的table裡面，能夠區辨所有data的特徵叫做key，是能把所有人define出來的一個feature，keyword就是可以做為document的key的word，是具有區辨意義的代表字；關鍵字∕詞是意義上最有代表性的重要字。keyword跟關鍵字可以是一樣的字，但代表的意義不同。
一篇新聞裡的關鍵字應是該篇新聞中最具有意義的字，以我的觀點來看，新聞類別的文本中，關鍵字是以動詞為主，因為能夠透過動詞判斷該篇新聞事件主要發生的事件，例如棒球新聞中會有的「安打」以及社會新聞中的「殺」、「撞」等等。keyword可以透過TF-IDF的加權技術摘出，可能會是任何詞性的詞彙，不會限於具有意義的動詞、名詞及形容詞等等，以新聞來說不一定會是關鍵字。

### 2. 請給些例子說明，「什麼是一個字 (word)」？「什麼是一個字符 (character)」？而「什麼是一個「詞 (phrase)」？在 Computer Science 的領域裡，有個專有名詞叫 "token"，依前述的定義，請說明 "token" 和 word, character, phrase 之間有什麼異同。

word(詞)是語言系統之中具有意義的最小單位；character(字符)指的是語言系統中獨立的符號單位；而phrase(我更偏好翻譯成詞組)是word的集合，字句由短到長都有，具有特定意義。例如「蜻」、「蜓」為character(字符)；「蜻蜓」為word(字)；「蜻蜓在花園」為phrase(詞組)
以中文來說，因為有許多character具有獨立意義，所以character也可能是詞；而詞組一定是由一個以上的詞所組成，所以詞組不會是字符或是詞。
token在computer science中指一段不一定有意義的字串，然而以斷詞角度來看的話，為文本的子字串。假如有一個句子是"我看到蜻蜓在花園的水池上飛"，被分成"我"、"看到"、"蜻蜓在花園"、"的"、"水池"、"上飛"，這些都屬於token。是以可以依word、character或是phrase分割成token，又或著都不是，不一定要具有意義，就像上述例子中的"上飛"，即不屬於word、character或是phrase任何一種。


### 3. 只有中文 NLP 有斷詞的需求嗎？其它的語言的 NLP 是否也有斷詞的需求？請以實例 (而非文獻) 說明斷詞是否仍有其存在的必要性。
我認為每個語言的文本都需要經過單詞分割才能夠在電腦中運算，讓電腦先確認不同詞、詞性之間的關聯(如以中文來說「的」這個助詞，後面只會接名詞；或是英文的副詞後面只會接動詞或是形容詞等等)，才能依照該語言的特性去坐進一步的處理（如語意辨析、語言生成、翻譯等等）。
有些書面語言的詞跟詞之間會有分界標記，如西班牙文及英文詞跟詞間的空格、阿拉伯語會有獨特的首末字母等等，然而像是中文、日文等等每句話的字符都連在一起的語言就需要經過特別的斷詞系統設計。
舉例來說：
以中文來說：
「波羅的海是中歐和北歐之間的陸間海。」
如果沒有斷詞系統設定中「波羅的海」這個專有名詞，依照
以日文來說：
ははくちのなかにはえるきかん。(歯は口の中に生える器官)（牙齒是生長在口腔中的器官。）
前面兩個は分分別是名詞及格助詞，如果全都以平假名書寫字的話，沒有經過斷詞也可能被判斷成另外一個名詞はは(母親)。
以英文來說：
Certain people always want to maintain the status quo.
這句話中的status quo是一個中間有空格的名詞，不能單純以空格切開。

### 4. Out-of-vocabulary (OOV) 常是主流斷詞系統評估系統良率的一個指標，常見的說法是「oov rate 愈低，則表示系統愈完備」。請說明這個指標是否正確。
語言會一直創新，以中文為例，參考《不可能還在歸剛誒吧！接軌 Z 世代，2022 網路流行用語大彙集！》（PARTIPOST），2022年新出現的網路流行用語如「無fuck說」、「你彭佳慧唉」、「duck不必」、「安屎之亂」等等……都是從前沒在使用的新詞。
平常跟朋友之間談話也很有可能創造出新詞，如同我最近在朋友群組中看到的語句：「XX你又在偷臭我...就不能好我一下嗎？」，「好」跟「臭」原先都是形容詞，將「臭」當成動詞是2021年在電競圈開始流行的用法，意旨批評或是謾罵，也就是嘴的意思，我的好友就這個句勢，隨手便創造了一個將「好」當成動詞的用法，而且群組內的眾人都能迅速了解它的意義。
除了上述一些非正式書面用語的狀況之外，還有在新聞報導中，因為字數上的限制，一些專有名詞，如人名、機構名稱等，在標題使用或是同一篇文章內如果出現第二次的情況下，就會採用縮寫的方式呈現。只要出現一個新的機構或是一位先前相對沒有這麼有名的人，也會產生新的縮寫詞。
以上的例子，如果使用現行的斷詞系統，不新增字典便無法辨識涵義，因此我認為以OOV率來評估斷詞系統的良率是一個有瑕疵的判斷標準。


### 5. 請說明 WS (word segmentation)、POS (part-of-speech) tag 和 NER (named entity recognition) 各自是什麼？包括 Articut，請再自選兩個斷詞系統，並從應用的角度討論這三個系統的 WS、POS、NER 各自有什麼樣的優缺點（優、缺點請至少各列兩點)。

WS(word segmentation)是指字詞分割，；POS(part-of-speech) tag是詞性標記，為每個單詞指定(標上)相應的詞性；NER (named entity recognition)
Articut：
優：
1. WS、POS及NER標記正確率高 
2. NER種類很多 
3. 可以調整WS深度，以level區分
4. 能夠辨別實義詞(content word) 
缺：
1. 無法處理縮寫詞及長機構名稱

Jieba：
優：
1. WS速度快，新增字典容易
2. WS有三種模式精確、全和搜尋引擎模式，對應不同功能
缺：
1. 無法處理沒有在字典裡的詞(加新詞的字典會影響最終結果，不加新詞又沒辦法處理在字典中沒有的字) 
2. 一開始的模型是用簡體中文去做，繁體中文WS的正確率相對較低 
3. 無法區辨NER標記中不同人名意義的相近程度。

CKIP：
優：
1. 除了WS及POS外還提供了句子的parsing tree  
2. 能夠辨別實義詞(content word) 
3. 除了WS外還能讓詞義的資料視覺化
缺：
1. 資料庫大，WS運算時長久 
2. WS傳輸量有很低的限制(院外一次限兩千字)  
3. WS、POS以及NER的正確率計算指標不明
